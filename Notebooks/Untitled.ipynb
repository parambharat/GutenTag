{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from collections import defaultdict, OrderedDict\n",
    "import settings\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "from nltk import stem\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = os.path.join(settings.project_root, 'tmp', 'data_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "humor_file = os.path.join(base_path,'Humor.csv')\n",
    "family_file = os.path.join(base_path,'Family.csv')\n",
    "romance_file = os.path.join(base_path,'Romance.csv')\n",
    "sci_fi_file = os.path.join(base_path,'Sci-Fi.csv')\n",
    "supernatural_file = os.path.join(base_path,'Supernatural.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = \"\"\"\n",
    "a about above across after afterwards again against all almost alone along already also although always am among amongst amoungst amount an and another any anyhow anyone anything anyway anywhere are around as at back be\n",
    "became because become becomes becoming been before beforehand behind being below beside besides between beyond bill both bottom but by call can\n",
    "cannot cant co computer con could couldnt cry de describe\n",
    "detail did didn do does doesn doing don done down due during\n",
    "each eg eight either eleven else elsewhere empty enough etc even ever every everyone everything everywhere except few fifteen\n",
    "fify fill find fire first five for former formerly forty found four from front full further get give go\n",
    "had has hasnt have he hence her here hereafter hereby herein hereupon hers herself him himself his how however hundred i ie\n",
    "if in inc indeed interest into is it its itself keep last latter latterly least less ltd\n",
    "just\n",
    "kg km\n",
    "made make many may me meanwhile might mill mine more moreover most mostly move much must my myself name namely\n",
    "neither never nevertheless next nine no nobody none noone nor not nothing now nowhere of off\n",
    "often on once one only onto or other others otherwise our ours ourselves out over own part per\n",
    "perhaps please put rather re\n",
    "quite\n",
    "rather really regarding\n",
    "same say see seem seemed seeming seems serious several she should show side since sincere six sixty so some somehow someone something sometime sometimes somewhere still such system take ten\n",
    "than that the their them themselves then thence there thereafter thereby therefore therein thereupon these they thick thin third this those though three through throughout thru thus to together too top toward towards twelve twenty two un under\n",
    "until up unless upon us used using\n",
    "various very very via\n",
    "was we well were what whatever when whence whenever where whereafter whereas whereby wherein whereupon wherever whether which while whither who whoever whole whom whose why will with within without would yet you\n",
    "your yours yourself yourselves\n",
    "\"\"\"\n",
    "STOPWORDS = frozenset(w for w in STOPWORDS.split() if w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_frequencies(infile, remove_stops=True):\n",
    "    stemmer = stem.PorterStemmer()\n",
    "    token_dict = defaultdict(int)\n",
    "    for line in open(infile, 'r'):\n",
    "        for token in line.split(',')[1].split():\n",
    "            if not token.lower() in STOPWORDS and len(token) > 3:\n",
    "                token_dict[stemmer.stem(token.lower())] += 1\n",
    "    token_dict = OrderedDict((item, token_dict[item]) for item in \n",
    "                             sorted(token_dict, key=token_dict.get, reverse=True))\n",
    "    return token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataFrame():\n",
    "    df = pd.DataFrame()\n",
    "    for data_file in [humor_file,family_file,romance_file,sci_fi_file,supernatural_file]:\n",
    "        freq_data = get_frequencies(data_file)\n",
    "        df = pd.concat([df, pd.Series(freq_data)])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_dataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_data(hist):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    X = np.arange(len(hist))\n",
    "    plt.bar(X, hist.values(), align='center', width=0.5)\n",
    "    plt.xticks(X, hist.keys())\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=90)\n",
    "    ymax = max(hist.values()) + 100\n",
    "    plt.ylim(0, ymax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_top_words(indict, n=10, m=0):\n",
    "    return OrderedDict((key,value) for key, value in indict.items()[m:n+m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data_file in [humor_file,family_file,romance_file,sci_fi_file,supernatural_file]:\n",
    "    freq_data = get_frequencies(data_file)\n",
    "    freq_data = get_top_words(freq_data, n=25, m=0)\n",
    "    plot_data(freq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jensen_shannon(u, v):\n",
    "    u = np.array(u)\n",
    "    v = np.array(v)\n",
    "    _u = u / norm(u, ord=1)\n",
    "    _v = v / norm(v, ord=1)\n",
    "    _M = 0.5 * (_u + _v)\n",
    "    d = 0.5 * (entropy(_u, _M) + entropy(_v, _M))\n",
    "    if np.isinf(d):\n",
    "        d = 0\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.stats import entropy\n",
    "from numpy.linalg import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "s_matrix = csr_matrix((data, (row, col)), shape=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_matrix = csc_matrix(np.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_similarities(mat):\n",
    "    cols_sum = mat.getnnz(axis=0)\n",
    "    ab = mat.T * mat\n",
    "\n",
    "    # for rows\n",
    "    aa = np.repeat(cols_sum, ab.getnnz(axis=0))\n",
    "    # for columns\n",
    "    bb = cols_sum[ab.indices]\n",
    "\n",
    "    similarities = ab.copy()\n",
    "    similarities.data /= (aa + bb - ab.data)\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jaccard_similarities(s_matrix).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
